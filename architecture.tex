% !TEX root = ./arock_pkg_main.tex
\section{Architecture}

The toolbox is designed to have several layers that represent different mathematical components, making it easy to understand, maintain, and upgrade by a user. Specifically, it has the following layers: Multicore Drivers, Kernels, Schemes, Operators, and Linear Algebra. 

\subsection{Interfaces}
To maintain the mathematical abstraction between layers, interfaces are used. Layers interact through their interfaces.
Consider, for example,  the Operator Interface:

\begin{lstlisting}[language=C++,label={Operator_Interface}]
struct Operator_Interface {
  // returns the operator evaluated on v at the given index
   double operator() (Vector* v, int index);
  // returns the operator evaluated on v at the given index
   double operator() (double val, int index);
  // applies full operator to v_in and write it to v_out
   void operator() (Vector* v_in, Vector* v_out);
  // update the cached variables
  void update_cache_vars (double old_x_i, double new_x_i, int index);
  // update the step size
  void update_step_size (double step_size_) ;
 };
\end{lstlisting}

The Operator Interface only includes the function declarations, not the implementation of the functions themselves. For an object to belong to the Operator layer, it must implement these functions.
As a result, implementation is decoupled from usage.
%This allows for easy maintenance and specialization of code while not affecting the user's code.

The following is a brief description of each layer and how it interacts with the layers above and below it.

\subsection{Multicore Drivers}
The layer of Multicore Drivers is responsible of create threads (corresponding to agents in algorithm \ref{alg:fbs_l1_log}). If a controller (see later) is used, then a thread for the controller will also be created. When a thread is created, the layer grants it access to certain coordinates. Both thread creation and coordinate access are determined by the user-specified coordinate update scheme. For example, if the user specifies the random parallel scheme and ten threads, then ten threads (or nine threads plus a controller thread) will be created and each will  be granted to access all the coordinates (the ``random" selection rule will be passed to threads). Other schemes such as block-cyclic parallel, Gauss-Seidel parallel, as well as single-threaded schemes are implemented, too. 

This layer is also responsible for waiting for all threads to complete before returning the result to the user and terminating the algorithm.    

Therefore, this layer can be understood as a mapping from a coordinate update scheme to a thread manager. Note that this layer leaves the operations inside each thread to the other layers. As such, any user-specified operators, splitting scheme, and parameters are passed transparently to the next layer.

Most users can treat this layer as a black box. Only when a new coordinate update scheme or a new way to generate threads is desired, does the user need to make modifications to the code of this layer.


\subsection{Kernel}


The Multicore Drivers Layer is responsible for creating agents, and the Kernel layer contains the agents types that can be created.
A worker agent chooses an index according to its rule, and, using a scheme object, computes a coordinate update.
As such, The Kernel layer can be seen as different realizations of the while loop stucture of algorithm \ref{alg:fbs_l1_log}.
In addition, the Kernel layer contains controller agents.
A controller agent manages the worker agents by choosing stepsizes to accelerate convergence.
The current controller agent monitors convergence by maintaining an approximate fixed point residual.

Agents are realized as c++11 threads and a c++11 thread is constructed from a function.
As a result, each worker and controller type, has  a corresponding function.
If the user wishes to introduce a new agent type, they need only write a function that implements the logic of the new agent.
They must then modify the Multicore Driver layer to recognize their new agent type as an option.

\subsection{Schemes}

Objects in the Scheme Layer are used by by worker agents in the Kernel Layer to run a multicore solver.
Schemes are objects with, at minimum, member functions as defined by the Scheme Interface.
\begin{lstlisting}[language=C++]
struct Scheme_Interface {
void update_params(Params* params);
double operator() (int index);
};
\end{lstlisting}
By providing a coordinate to the scheme object, a coordinate update is applied.
The Scheme Interface is very lightweight, as schemes can be quite varied in nature.

The Scheme layer is intended to model the mathematical dvide between optimization methods and applications of optimization methods to specific problems.
 For example, equation \ref{eq:fbs_l1_log} is Forward Backward Splitting (also referred as Proximal Gradient Method) applied to a specific problem, sparse logistic regression.
 A realization of  Forward Backward Splitting is constructed by composing a specific  Forward Operator and a specific Backward Operator.
 At a high level, the scheme layer implements algorithm factories.
 We provide implemenations of the following schemes: \texttt{ForwardBackwardSplitting}, \texttt{ProximalPointAlgorithm},  \texttt{GradientDescent}, \texttt{BackwardForwardSplitting}, and \texttt{PeacemanRachfordSplitting}.

Objects in the Scheme Layer are implemented as templates.
Templates, in c++, are code factories.
 Based upon the arguments passed to the template, c++ automatically constructs a corresponding object type for the user.
For example, in code snippet \ref{fbs_l1_log_code} the scheme type of \texttt{fbs} is defined by the arguments to the forward backward splitting template, \texttt{forward\_grad\_for\_log\_loss<SpMat>}, and \texttt{prox\_l1}. 
 Different arguments to the template result in different coordinate update schemes.

A user can construct solvers by choosing a scheme, and selecting operator objects to specialize the scheme to a specific problem. 
If the provided schemes are not sufficient, the user may implement their own scheme.
The user is encouraged to use objects from the Operator Layer as building blocks, but direct implementaiton of a coordinate update scheme is allowed.

\subsection{Operators}

Operators are objects with, at minimum, member functions as defined by code snippet \ref{Operator_Interface}, the Operator Interface..
Many optimization algorithms  have computational commonalities.
For instance, all first order methods interacting with equation \ref{eq:l1_log} will need to compute the gradient of logistic regression.
The Operator layer formalizes these computatioanl commonallities by encapsulating them in Operator objects.
At a high level, the Operator Layer contains the atomic components of optimization.
In code snippet \ref{fbs_l1_log_code}, a coordinate update scheme is constructed simply by creating two Operators, and handing them to a Scheme object.
Operator objects allow the user to construct algorihtms as written on paper without worrying about implementing the low level computations themselves.

The construction of an Operator object depends upon what is necessary to compute its coordinate update efficiently.
For example, \texttt{forward\_grad\_for\_log\_loss<SpMat>} requires the matrix \texttt{A}, the vector \texttt{b}, a stepsize \texttt{eta},  and, to maintain computational efficiency, the cached variable \texttt{Atx}.
In some cases the data may be dense, sparse, or best represented by a function (consider the wavelet tranform).
Operators, to allow for different data respresentations, are templatized on their data.
The matrix \texttt{A}, in this example, is sparse.

If the user needs a specialzied version of an existing operator, they can use C++'s template specialization to implement it.
If the user needs a new operator,  the new operator can interact seamlessly with the existing toolbox as long as the Operator Interface is obeyed.





\subsection{Linear Algebra}

We use Eigen package to represent sparse matrices and vectors. 
Sparse linear algebra is provided through an interface to Eigen and Sparse BLAS.
Dense linear algebra is provided through an interface to BLAS. 







